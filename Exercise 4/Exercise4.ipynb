{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Model yoinked from https://github.com/spro/char-rnn.pytorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HELPER FUNCTIONS\n",
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "\n",
    "# Reading and un-unicode-encoding data\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "def read_file(filename):\n",
    "    file = unidecode.unidecode(open(filename).read())\n",
    "    return file, len(file)\n",
    "\n",
    "# Turning a string into a tensor\n",
    "\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        try:\n",
    "            tensor[c] = all_characters.index(string[c])\n",
    "        except:\n",
    "            continue\n",
    "    return tensor\n",
    "\n",
    "# Readable time elapsed\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model class\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, model=\"gru\", n_layers=1):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.model = model.lower()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        if self.model == \"gru\":\n",
    "            self.rnn = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        elif self.model == \"lstm\":\n",
    "            self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        batch_size = input.size(0)\n",
    "        encoded = self.encoder(input)\n",
    "        output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n",
    "        output = self.decoder(output.view(batch_size, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def forward2(self, input, hidden):\n",
    "        encoded = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.rnn(encoded.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        if self.model == \"lstm\":\n",
    "            return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)),\n",
    "                    Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)))\n",
    "        return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"shakespear.txt\"\n",
    "file, file_len = read_file(filename)\n",
    "lr = 0.01\n",
    "hidden_size = 100\n",
    "n_layers = 2\n",
    "chunk_len = 200\n",
    "batch_size = 100\n",
    "epochs = 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_set(chunk_len, batch_size):\n",
    "    inp = torch.LongTensor(batch_size, chunk_len)\n",
    "    target = torch.LongTensor(batch_size, chunk_len)\n",
    "    for bi in range(batch_size):\n",
    "        start_index = random.randint(0, file_len - chunk_len)\n",
    "        end_index = start_index + chunk_len + 1\n",
    "        chunk = file[start_index:end_index]\n",
    "        inp[bi] = char_tensor(chunk[:-1])\n",
    "        target[bi] = char_tensor(chunk[1:])\n",
    "    inp = Variable(inp)\n",
    "    target = Variable(target)\n",
    "    inp.to(device)\n",
    "    target.to(device)\n",
    "    return inp, target\n",
    "\n",
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden(batch_size)\n",
    "    decoder.to(device)\n",
    "    hidden.to(device)\n",
    "    inp.to(device)\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[:,c].to(device), hidden.to(device))\n",
    "        loss += criterion(output.view(batch_size, -1).to(device), target[:,c].to(device))\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / chunk_len\n",
    "\n",
    "def save():\n",
    "    save_filename = os.path.splitext(os.path.basename(filename))[0] + '.pt'\n",
    "    torch.save(decoder, save_filename)\n",
    "    print('Saved as %s' % save_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(decoder, prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden(1)\n",
    "    prime_input = Variable(char_tensor(prime_str).unsqueeze(0))\n",
    "\n",
    "    \n",
    "    hidden.to(device)\n",
    "    prime_input.to(device)\n",
    "    decoder.to(device)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[:,p].to(device), hidden.to(device))\n",
    "        \n",
    "    inp = prime_input[:,-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp.to(device), hidden.to(device))\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = Variable(char_tensor(predicted_char).unsqueeze(0))\n",
    "        inp.to(device)\n",
    "\n",
    "    return predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2000 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 100/2000 [00:30<10:02,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 30s (100 5%) 1.7257]\n",
      "Which ardnest and and that her with of and the lisless to all the mand's good buty and sir,\n",
      "You somans \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 200/2000 [01:00<09:52,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1m 0s (200 10%) 1.6021]\n",
      "Why dike an I them of the\n",
      "match the true enougne; bid the maid.\n",
      "\n",
      "ROMEO:\n",
      "And thee my might a tongue, my \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 300/2000 [01:30<08:59,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1m 30s (300 15%) 1.5124]\n",
      "Where the love with himself's-ours!\n",
      "\n",
      "KING EDWARD IV:\n",
      "\n",
      "Lord:\n",
      "A po have head of fie.\n",
      "\n",
      "PRINCE EDWARD:\n",
      "Not \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 400/2000 [01:59<08:08,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1m 59s (400 20%) 1.4459]\n",
      "Which a lips of them and recovere?\n",
      "\n",
      "MARCIUS:\n",
      "Why, the gracious speak, and gentlecion and the sing,\n",
      "You \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 500/2000 [02:29<07:53,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2m 29s (500 25%) 1.4541]\n",
      "Where we do gundst not to the findly you have send the day,\n",
      "And that sorrow yet better he will cram:\n",
      "W \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 600/2000 [02:59<07:15,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2m 59s (600 30%) 1.4331]\n",
      "What is not present to our trust on his Lady:\n",
      "That I say you on them to the stobence with her,\n",
      "And we  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 700/2000 [03:29<06:24,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3m 29s (700 35%) 1.4330]\n",
      "What's a death all sildity with\n",
      "it to the white to summied how too that I would.\n",
      "Then, my lord's broth \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 800/2000 [03:57<05:58,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3m 57s (800 40%) 1.4010]\n",
      "Whear, never presant; and she professor with and First his way or\n",
      "sirrings of battle daughter,\n",
      "I charr \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 900/2000 [04:26<05:21,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4m 26s (900 45%) 1.4006]\n",
      "Whe did for prove answer us can she request\n",
      "When it it fault, quiet my brother Aufidius,\n",
      "You will you  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1000/2000 [04:55<05:07,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4m 55s (1000 50%) 1.3955]\n",
      "Whou wert thou did bid his life:\n",
      "What my lorders deyer her would revil the horse when\n",
      "sups for thee, i \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 1100/2000 [05:24<04:25,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5m 24s (1100 55%) 1.3738]\n",
      "Which he could?\n",
      "\n",
      "ESCALUS:\n",
      "Why, one is such him father.\n",
      "\n",
      "MENENIUS:\n",
      "The flatter, coverful noble friared  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1200/2000 [05:53<04:04,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5m 53s (1200 60%) 1.3779]\n",
      "Whapon from hold the Lord Warwick,\n",
      "Shook at nine Master the bid him convey:\n",
      "Who was that is partunes t \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1300/2000 [06:22<03:33,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6m 22s (1300 65%) 1.3752]\n",
      "What wonder than I prepared\n",
      "This far with mode, let the thought to a bawd.\n",
      "Come, the boy is war and ha \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1400/2000 [06:51<03:01,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6m 51s (1400 70%) 1.3528]\n",
      "Which scrath our love was? had you unknown these\n",
      "here is the death hates to be have done?\n",
      "\n",
      "DUKE OF YOR \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1500/2000 [07:20<02:38,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7m 20s (1500 75%) 1.3446]\n",
      "While, magness you?\n",
      "\n",
      "ISABELLA:\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord Mawars is made his return, he and ewel,\n",
      "Which thou \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1600/2000 [07:49<02:03,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7m 49s (1600 80%) 1.3178]\n",
      "Which battle and that to hear, give you.\n",
      "\n",
      "ROMEO:\n",
      "The despair?\n",
      "\n",
      "POLIXENES:\n",
      "Come, and to what know, peat \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1700/2000 [08:17<01:31,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8m 17s (1700 85%) 1.3536]\n",
      "What shall appeal common'd that begin,\n",
      "That fetch the senself and thou saugher hours,\n",
      "But captive what \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 1800/2000 [08:46<01:05,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8m 46s (1800 90%) 1.3545]\n",
      "Which is more speak.\n",
      "\n",
      "GREMIO:\n",
      "Where it say you, sweet sign thereby with more?\n",
      "\n",
      "ANTONIO:\n",
      "He should act  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 1900/2000 [09:15<00:31,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9m 15s (1900 95%) 1.3687]\n",
      "Whither and his sons!\n",
      "\n",
      "BUCKINGHAM:\n",
      "Why, daughter than one for bastagenous\n",
      "To that you are far to see t \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [09:45<00:00,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9m 45s (2000 100%) 1.3445]\n",
      "What he were report for the brieved\n",
      "Thou shalt come over upon Marcius, if I have have restrave.\n",
      "I must \n",
      "\n",
      "Saving...\n",
      "Saved as shakespear.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "decoder = CharRNN(\n",
    "    n_characters,\n",
    "    hidden_size,\n",
    "    n_characters,\n",
    "    n_layers=n_layers,\n",
    ")\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "decoder.to(device)\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "try:\n",
    "    print(\"Training for %d epochs...\" % epochs)\n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        loss = train(*random_training_set(chunk_len, batch_size))\n",
    "        loss_avg += loss\n",
    "        all_losses.append(loss)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / epochs * 100, loss))\n",
    "            print(generate(decoder.to(device), 'Wh', 100), '\\n')\n",
    "\n",
    "    print(\"Saving...\")\n",
    "    save()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Saving before quit...\")\n",
    "    save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities = [math.exp(lossitem) for lossitem in all_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x265c32034f0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Perplexity\")\n",
    "\n",
    "ax.set_title(\"Perplexity vs Epochs\")\n",
    "\n",
    "ax.plot(range(1,epochs+1), perplexities, label=\"Perplexity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ztgAK \n",
      " ztgAKn as it since any to know\n",
      "When it is done much me arms.\n",
      "\n",
      "PETRUCHIO:\n",
      "The month as he cannot restrain  \n",
      "\n",
      "xQKzm \n",
      " xQKzmen shall prove\n",
      "Rest this durreal that he such seat, and done you\n",
      "I goess away\n",
      "Thou shalt be entray i \n",
      "\n",
      "xMHzw \n",
      " xMHzwear the fair sirnected\n",
      "Live all their common that farewell: and I would he would\n",
      "And then from the c \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def get_random_string(length):\n",
    "    result_str = ''.join(random.choice(string.ascii_letters + string.digits + ' ') for i in range(length))\n",
    "\n",
    "    return result_str\n",
    "\n",
    "\n",
    "ranstr = get_random_string(5)\n",
    "print(ranstr, '\\n', generate(decoder.to(device), ranstr, 100), '\\n')\n",
    "ranstr = get_random_string(5)\n",
    "print(ranstr, '\\n', generate(decoder.to(device), ranstr, 100), '\\n')\n",
    "ranstr = get_random_string(5)\n",
    "print(ranstr, '\\n', generate(decoder.to(device), ranstr, 100), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \n",
      " The sunners thy mother to make you and shack\n",
      "Because upon me and seems your sucks, and I may risonus,\n",
      "T \n",
      "\n",
      "What is \n",
      " What is and corret?\n",
      "\n",
      "FRIAR LAURENCE:\n",
      "Thy hieved from heavetry seen for my wrong;\n",
      "Let me a rumiss in find by \n",
      "\n",
      "Shall I give \n",
      " Shall I give me then that you have there I be\n",
      "reast now the lets than but the sunsome again:\n",
      "I should strike me  \n",
      "\n",
      "X087hNYB BHN BYFVuhsdbs \n",
      " X087hNYB BHN BYFVuhsdbs\n",
      "And till you devil in the captain an ear:\n",
      "Take thee gentleman discommbed raped.\n",
      "\n",
      "LEONTES:\n",
      "And more  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ranstr = 'The'\n",
    "print(ranstr, '\\n', generate(decoder.to(device), ranstr, 100), '\\n')\n",
    "ranstr = 'What is'\n",
    "print(ranstr, '\\n', generate(decoder.to(device), ranstr, 100), '\\n')\n",
    "ranstr = 'Shall I give'\n",
    "print(ranstr, '\\n', generate(decoder.to(device), ranstr, 100), '\\n')\n",
    "ranstr = 'X087hNYB BHN BYFVuhsdbs'\n",
    "print(ranstr, '\\n', generate(decoder.to(device), ranstr, 100), '\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
